# Configuração do Agente RAG de Q&A com PDF

# Configurações de Chunking
chunking:
  tamanho_chunk: 1000
  sobreposicao_chunk: 200
  estrategia: "fixed"  # Opções: "fixed", "semantic"

# Configurações de Recuperação
recuperacao:
  top_k: 5
  limiar_similaridade: 0.7
  usar_reranking: false

# Configurações do LLM
# Provedores suportados: openai, anthropic, ollama ou llama (local)
# Para Ollama/Llama, configure OLLAMA_HOST e OLLAMA_PORT no .env
llm:
  temperatura: 0.7
  max_tokens: 2000
  streaming: true

# Configurações ChromaDB
chromadb:
  nome_colecao: "documentos_pdf"
  distancia_metrica: "cosine"  # Opções: "cosine", "l2", "ip"

# Configurações de Upload
upload:
  max_tamanho_mb: 50
  formatos_permitidos:
    - "pdf"
  diretorio_uploads: "./data/uploads"

# Configurações da Aplicação
app:
  nome: "Agente Q&A com PDF"
  versao: "0.1.0"
  descricao: "Sistema de perguntas e respostas baseado em documentos PDF usando RAG"
  idioma: "pt-BR"
